{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "A1. Getting MODIS URLs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Access to MODIS data is now through `http`, which means that previous methods using `ftp` no longer operate.\n",
      "\n",
      "In some ways, this complicates automatic download (also, download seems now to be throttled, which means it takes longer to access the data).\n",
      "\n",
      "That said, you can of course still easily order data through NASA tools such as [reverb](http://reverb.echo.nasa.gov).\n",
      "\n",
      "Some tools have been developed to allow automated access to MODIS products from Python, such as [get_modis](https://github.com/jgomezdans/get_modis), but here, we will demonstrate how you can do it yourself, semi-automatically.\n",
      "\n",
      "We will see that a large part of the overhead and complexity is negotiating the directory structure.\n",
      "\n",
      "We have provided a shell programme [`zat`](files/python/zat) that will produce a list of urls of the MODIS products on the USGS server (use `zat > ` [`urls.txt`](files/data/robot.txt)), which you would probably find more convenient than this section. \n",
      "\n",
      "So, only go through section A1 if you are particularly intererested in trawling directories with http ...\n",
      "\n",
      "Once we have a full list of the urls of the hdf files that we want, life is much simpler. Such a list of urls is *exactly* what  [reverb](http://reverb.echo.nasa.gov) supplies you with."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "A1.1 Identify the server and directory structure"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, you need to identify which datasets you want. You should explore the data products e.g. through [reverb](http://reverb.echo.nasa.gov) to do this.\n",
      "\n",
      "If you go through the ordering system for one tile of these products, you can get the information you need for further data download. When you come to order the data, it will give you a download file.\n",
      "\n",
      "As an example:\n",
      "\n",
      "- MODIS LAI/fAPAR for Trerra and Aqua 8 day composite for 17 Jan 2013 for tile h18v03"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2013.01.17/MCD15A2.A2013017.h18v03.005.2013026065052.hdf\n",
      "http://e4ftl01.cr.usgs.gov/WORKING/BRWS/Browse.001/2013.01.26/BROWSE.MCD15A2.A2013017.h18v03.005.2013026065052.1.jpg\n",
      "http://e4ftl01.cr.usgs.gov/WORKING/BRWS/Browse.001/2013.01.26/BROWSE.MCD15A2.A2013017.h18v03.005.2013026065052.2.jpg\n",
      "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2013.01.17/MCD15A2.A2013017.h18v03.005.2013026065052.hdf.xml"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "A1.2 Identify the available dates"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From this, we see that the server is `e4ftl01.cr.usgs.gov`, that the `hdf` data (the spatial dataset we want) for the product `MCD15A2` version `005` is in the directory `MODIS_Composites/MOTA/MCD15A2.005`.\n",
      "\n",
      "Below that, we have the date and then the filename.\n",
      "\n",
      "Let's use `urllib2` to explore this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2\n",
      "url_base = 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005'\n",
      "response = urllib2.urlopen(url_base)\n",
      "html = response.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print the first 30 lines\n",
      "html.split('\\n')[:30]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is an html directory listing. We can identify the directories as lines that contain `[DIR]`.\n",
      "\n",
      "We can use `find` to identify lines that have this field:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dirs = []\n",
      "for line in html.split('\\n'):\n",
      "    if line.find('[DIRS]'):\n",
      "        dirs.append(line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# or more succinctly\n",
      "dirs = [line for line in html.split('\\n') if line.find('[DIR]') != -1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dirs[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We notice that the first such line is the directory listing information, so, what we really want is:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dirs = [line for line in html.split('\\n') if line.find('[DIR]') != -1][1:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dirs[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The subdirectory name is jusr after the field `href=\"`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dirs[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dirs[1].split('href=\"')[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dirs[1].split('href=\"')[1].split('/\">')[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, in this case, we can get the subdirectory names with:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dirs = [line.split('href=\"')[1].split('/\">')[0] for line in html.split('\\n') if line.find('[DIR]') != -1][1:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print the first 10\n",
      "dirs[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The pattern is `YYYY.MM.DD`. So we could split these as we go along. It would be convenient to have this as a numpy array:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dirs = np.array([line.split('href=\"')[1].split('/\">')[0].split('.') \\\n",
      "                 for line in html.split('\\n') if line.find('[DIR]') != -1][1:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dirs[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_years = np.sort(np.unique(dirs[:,0]))\n",
      "all_months = np.sort(np.unique(dirs[:,1]))\n",
      "all_doys = np.sort(np.unique(dirs[:,2]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "years,months,doys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "A1.3 Identify the datasets"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We know the full url is of the form:\n",
      "\n",
      "`http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2013.01.17/MCD15A2.A2013017.h18v03.005.2013026065052.hdf\n",
      "`\n",
      "\n",
      "Simplifying what we did above:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2\n",
      "url_base = 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005'\n",
      "response = urllib2.urlopen(url_base)\n",
      "dirs = np.array([line.split('href=\"')[1].split('/\">')[0] for line in html.split('\\n') if line.find('[DIR]') != -1][1:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "years = np.array([i.split('.')[0] for i in dirs])\n",
      "# year mask\n",
      "year = '2012'\n",
      "mask = (year == years)\n",
      "sub_dirs = dirs[mask]\n",
      "print sub_dirs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test with first one\n",
      "this_date = sub_dirs[0]\n",
      "\n",
      "url_date = url_base + '/' + this_date\n",
      "print url_date\n",
      "response1 = urllib2.urlopen(url_date)\n",
      "html1 = response1.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print the first 21 lines\n",
      "html1.split('\\n')[:21]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We note that the directory contains data for all tiles.\n",
      "\n",
      "Lets filter only lines that have the tile we want in:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tile = 'h18v03'\n",
      "lines = [line for line in html1.split('\\n') if line.find(tile) != -1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want the `.hdf` file, so refine the filter:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tile = 'h18v03'\n",
      "hdf_lines = [i for i in [line for line in html1.split('\\n') \\\n",
      "                         if line.find(tile) != -1] if i.find('.hdf\"') != -1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hdf_lines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now split this to get the filename we want:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hdf_lines[0].split('<a href=\"')[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hdf_lines[0].split('<a href=\"')[1].split('\">')[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, putting all of that together:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tile = 'h18v03'\n",
      "hdf_lines = [i for i in [line for line in html1.split('\\n') \\\n",
      "                         if line.find(tile) != -1] if i.find('.hdf\"') != -1]\n",
      "hdf_file = hdf_lines[0].split('<a href=\"')[1].split('\">')[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "A1.4 Some code for MODIS LAI filenames for a year"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The http access is quite slow, so this may take some minutes to run."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "year = '2012'\n",
      "tile = 'h18v03'\n",
      "\n",
      "\n",
      "hdf_files = []\n",
      "\n",
      "import urllib2\n",
      "\n",
      "# base URL for the product\n",
      "url_base = 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005'\n",
      "\n",
      "response = urllib2.urlopen(url_base)\n",
      "html = response.read()\n",
      "\n",
      "dirs = np.array([line.split('href=\"')[1].split('/\">')[0] for line in html.split('\\n') if line.find('[DIR]') != -1][1:])\n",
      "\n",
      "# identify years\n",
      "years = np.array([i.split('.')[0] for i in dirs])\n",
      "# year mask\n",
      "mask = (year == years)\n",
      "sub_dirs = dirs[mask]\n",
      "\n",
      "for this_date in sub_dirs:\n",
      "    url_date = url_base + '/' + this_date\n",
      "    response1 = urllib2.urlopen(url_date)\n",
      "    html1 = response1.read()\n",
      "    hdf_lines = [i for i in [line for line in html1.split('\\n') \\\n",
      "                             if line.find(tile) != -1] if i.find('.hdf\"') != -1]\n",
      "    hdf_file = url_date + '/' + hdf_lines[0].split('<a href=\"')[1].split('\">')[0]\n",
      "    hdf_files.append(hdf_file+'\\n')\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hdf_files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "['http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.01.01/MCD15A2.A2012001.h18v03.005.2012017211211.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.01.09/MCD15A2.A2012009.h18v03.005.2012019043358.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.01.17/MCD15A2.A2012017.h18v03.005.2012026072219.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.01.25/MCD15A2.A2012025.h18v03.005.2012052124727.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.02.02/MCD15A2.A2012033.h18v03.005.2012042063805.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.02.10/MCD15A2.A2012041.h18v03.005.2012050093545.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.02.18/MCD15A2.A2012049.h18v03.005.2012068144450.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.02.26/MCD15A2.A2012057.h18v03.005.2012068140556.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.03.05/MCD15A2.A2012065.h18v03.005.2012075021755.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.03.13/MCD15A2.A2012073.h18v03.005.2012083010705.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.03.21/MCD15A2.A2012081.h18v03.005.2012090131310.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.03.29/MCD15A2.A2012089.h18v03.005.2012107201241.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.04.06/MCD15A2.A2012097.h18v03.005.2012108151105.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.04.14/MCD15A2.A2012105.h18v03.005.2012116125611.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.04.22/MCD15A2.A2012113.h18v03.005.2012122072726.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.04.30/MCD15A2.A2012121.h18v03.005.2012137221353.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.05.08/MCD15A2.A2012129.h18v03.005.2012142001303.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.05.16/MCD15A2.A2012137.h18v03.005.2012153021225.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.05.24/MCD15A2.A2012145.h18v03.005.2012160131154.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.06.01/MCD15A2.A2012153.h18v03.005.2012166161810.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.06.09/MCD15A2.A2012161.h18v03.005.2012170081629.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.06.17/MCD15A2.A2012169.h18v03.005.2012181134249.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.06.25/MCD15A2.A2012177.h18v03.005.2012188150322.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.07.03/MCD15A2.A2012185.h18v03.005.2012208181034.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.07.11/MCD15A2.A2012193.h18v03.005.2012202143905.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.07.19/MCD15A2.A2012201.h18v03.005.2012215131930.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.07.27/MCD15A2.A2012209.h18v03.005.2012219144505.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.08.04/MCD15A2.A2012217.h18v03.005.2012228215135.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.08.12/MCD15A2.A2012225.h18v03.005.2012234105243.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.08.20/MCD15A2.A2012233.h18v03.005.2012242101958.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.08.28/MCD15A2.A2012241.h18v03.005.2012250183145.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.09.05/MCD15A2.A2012249.h18v03.005.2012261232303.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.09.13/MCD15A2.A2012257.h18v03.005.2012270115138.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.09.21/MCD15A2.A2012265.h18v03.005.2012276134744.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.09.29/MCD15A2.A2012273.h18v03.005.2012297134237.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.10.07/MCD15A2.A2012281.h18v03.005.2012297140002.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.10.15/MCD15A2.A2012289.h18v03.005.2012299194646.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.10.23/MCD15A2.A2012297.h18v03.005.2012306163315.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.10.31/MCD15A2.A2012305.h18v03.005.2012314140504.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.11.08/MCD15A2.A2012313.h18v03.005.2012322095812.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.11.16/MCD15A2.A2012321.h18v03.005.2012335134248.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.11.24/MCD15A2.A2012329.h18v03.005.2012340181749.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.12.02/MCD15A2.A2012337.h18v03.005.2012346165145.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.12.10/MCD15A2.A2012345.h18v03.005.2012356133136.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.12.18/MCD15A2.A2012353.h18v03.005.2012363125136.hdf\\n',\n",
        " 'http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.12.26/MCD15A2.A2012361.h18v03.005.2013007202847.hdf\\n']"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's wrap this into a function and generalise it a bit:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In case download fails later, lets save this list `hdf_files`. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('files/data/lai_list.txt','w')\n",
      "f.writelines(hdf_files)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "A2 Pull Data from url"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This part is actually faster than doing all of that messing around with directories.\n",
      "\n",
      "You don't really want to have to do too much of the directory exploration, so it is *probably* a good idea to just periodically scan the whole structure and store that in a local file. You can then parse the local file much more easily (that is what we do in the main part of the class).\n",
      "\n",
      "This is achieved for instance with the shell [`zat`](files/python/zat) (use `zat > ` [`urls.txt`](files/data/robot.txt)) if you want to do an update, or just use the existing [url file](files/data/robot.txt)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2\n",
      "\n",
      "f = open('files/data/lai_list.txt','r')\n",
      "hdf_files = f.readlines()\n",
      "f.close()\n",
      "\n",
      "for url in hdf_files:\n",
      "    url = url.strip()\n",
      "    print url\n",
      "    response = urllib2.urlopen(url.strip())\n",
      "    ofile = 'files/data/' + url.split('/')[-1]\n",
      "    f = open(ofile,'w')\n",
      "    f.write(response.read())\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.01.01/MCD15A2.A2012001.h18v03.005.2012017211211.hdf\n",
        "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.01.09/MCD15A2.A2012009.h18v03.005.2012019043358.hdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.01.17/MCD15A2.A2012017.h18v03.005.2012026072219.hdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.01.25/MCD15A2.A2012025.h18v03.005.2012052124727.hdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.02.02/MCD15A2.A2012033.h18v03.005.2012042063805.hdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.02.10/MCD15A2.A2012041.h18v03.005.2012050093545.hdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.02.18/MCD15A2.A2012049.h18v03.005.2012068144450.hdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.02.26/MCD15A2.A2012057.h18v03.005.2012068140556.hdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.03.05/MCD15A2.A2012065.h18v03.005.2012075021755.hdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.03.13/MCD15A2.A2012073.h18v03.005.2012083010705.hdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.03.21/MCD15A2.A2012081.h18v03.005.2012090131310.hdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.03.29/MCD15A2.A2012089.h18v03.005.2012107201241.hdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.04.06/MCD15A2.A2012097.h18v03.005.2012108151105.hdf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://e4ftl01.cr.usgs.gov/MODIS_Composites/MOTA/MCD15A2.005/2012.04.14/MCD15A2.A2012105.h18v03.005.2012116125611.hdf"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}